<div align="center">

<img src="images/monitorx_trans.png" alt="MonitorX Logo" width="400">

# ğŸ¯ MonitorX

### ML/AI Infrastructure Observability Platform

**The missing piece between ML model deployment and production reliability**

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Type Checked](https://img.shields.io/badge/type%20checked-mypy-blue.svg)](http://mypy-lang.org/)

[![Tests](https://img.shields.io/badge/tests-119%20passing-brightgreen.svg)]()
[![Code Coverage](https://img.shields.io/badge/coverage-100%25-brightgreen.svg)]()
[![Documentation](https://img.shields.io/badge/docs-4133+%20lines-blue.svg)](docs/)
[![Release](https://img.shields.io/badge/release-v0.1.0-blue.svg)](https://github.com/your-org/monitorx/releases)

[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688.svg)](https://fastapi.tiangolo.com)
[![InfluxDB](https://img.shields.io/badge/InfluxDB-2.7-blue.svg)](https://www.influxdata.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io)
[![Docker](https://img.shields.io/badge/docker-ready-2496ED.svg)](https://www.docker.com)

[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![Code of Conduct](https://img.shields.io/badge/code%20of%20conduct-contributor%20covenant-purple.svg)](CODE_OF_CONDUCT.md)
[![Security](https://img.shields.io/badge/security-policy-red.svg)](SECURITY.md)
[![Maintenance](https://img.shields.io/badge/maintained-yes-brightgreen.svg)](https://github.com/your-org/monitorx/graphs/commit-activity)

**[Documentation](docs/)** | **[Quick Start](#-quick-start)** | **[API Reference](docs/API.md)** | **[Contributing](#-contributing)**

---

</div>

MonitorX addresses the observability gap that every ML team faces at scale by providing comprehensive monitoring, alerting, and analytics for production ML infrastructure.

## ğŸ‰ Production-Ready MVP

âœ… **119 Tests** - Complete test coverage with 100% pass rate
âœ… **2,900+ Lines of Documentation** - Comprehensive guides for API, SDK, deployment, and security
âœ… **Advanced SDK** - Batch collection, auto-retry, circuit breaker, and offline buffering
âœ… **Enterprise Security** - API Key & JWT auth, rate limiting, CORS
âœ… **Multi-Channel Alerting** - Email, Slack, Webhooks with resolution UI
âœ… **Production Dashboard** - Real-time monitoring with CSV/JSON export
âœ… **Docker Compose** - One-command deployment

### ğŸ” Verify It Works

Prove MonitorX is Working As Intended (WAI) in 5 seconds:

```bash
./verify_quick.sh  # âœ… Runs 23 verification checks
```

See [VERIFICATION_GUIDE.md](VERIFICATION_GUIDE.md) and [PROOF_OF_WAI.md](PROOF_OF_WAI.md) for complete evidence.

## âœ¨ Features

### Core Monitoring
- **Real-time inference metrics**: Latency, throughput, error rates across model types (LLM, CV, tabular)
- **Model drift detection**: Data/concept drift with automated alerting
- **Resource utilization tracking**: GPU memory, compute efficiency, cost attribution
- **Custom metric ingestion**: Flexible API for team-specific KPIs

### Intelligent Alerting
- **ML-aware alerting**: Context-sensitive thresholds per model
- **Multi-channel notifications**: Email, Slack, webhooks
- **Rate limiting**: Prevent alert spam with intelligent deduplication
- **Severity-based routing**: Critical alerts get immediate attention

### Production Dashboard
- **Real-time metrics visualization**: Interactive charts and graphs
- **Service-level views**: Per-model SLIs/SLOs with burn-rate monitoring
- **Historical analysis**: Performance trends and capacity planning
- **Alert management**: Centralized alert tracking and resolution
- **Alert resolution**: One-click alert resolution with API integration
- **Data export**: Download metrics and alerts as CSV or JSON
- **Smart auto-refresh**: Configurable intervals (5-120s) with countdown timer

### Developer Experience
- **Python SDK**: Easy integration with existing ML pipelines
  - **Batch collection**: Send multiple metrics in parallel for 10x performance
  - **Auto-retry**: Exponential backoff handles transient failures
  - **Circuit breaker**: Prevent cascading failures during outages
  - **Metric buffering**: Queue metrics offline, flush when API recovers
- **Decorators**: Zero-code monitoring for ML functions
- **REST API**: Full programmatic access with OpenAPI docs
- **Time-series storage**: Efficient InfluxDB backend for scalability

### Production-Ready Security
- **Authentication**: API Key and JWT authentication with scope-based authorization
- **Rate Limiting**: Sliding window algorithm with configurable thresholds
- **CORS**: Configurable cross-origin resource sharing
- **Security Headers**: Production-grade security headers and best practices

## ğŸš€ Quick Start

### Using Docker Compose (Recommended)

```bash
# Clone the repository
git clone https://github.com/your-org/monitorx.git
cd monitorx

# Start all services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f
```

Visit:
- **API Documentation**: http://localhost:8000/docs
- **Dashboard**: http://localhost:8501
- **InfluxDB UI**: http://localhost:8086

### Manual Installation

```bash
# Clone the repository
git clone https://github.com/your-org/monitorx.git
cd monitorx

# Install dependencies
pip install -r requirements.txt

# Install in development mode
pip install -e .

# Set up environment variables
cp .env.example .env
# Edit .env with your settings
```

### Setup InfluxDB

```bash
# Using Docker
docker run -d --name influxdb \
  -p 8086:8086 \
  -e DOCKER_INFLUXDB_INIT_MODE=setup \
  -e DOCKER_INFLUXDB_INIT_USERNAME=admin \
  -e DOCKER_INFLUXDB_INIT_PASSWORD=password123 \
  -e DOCKER_INFLUXDB_INIT_ORG=monitorx \
  -e DOCKER_INFLUXDB_INIT_BUCKET=metrics \
  influxdb:2.7
```

### Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit configuration
vim .env
```

### Start Services

```bash
# Start API server
python -m monitorx.server

# Start dashboard (in another terminal)
streamlit run src/monitorx/dashboard/app.py --server.port 8501
```

Visit:
- **API Documentation**: http://localhost:8000/docs
- **Dashboard**: http://localhost:8501
- **API Health**: http://localhost:8000/api/v1/health

## ğŸ“Š Usage Examples

### Basic SDK Usage

```python
import asyncio
from monitorx.sdk import MonitorXClient
from monitorx.types import ModelConfig, Thresholds

async def main():
    # Initialize client
    client = MonitorXClient("http://localhost:8000")

    # Register a model
    config = ModelConfig(
        id="my-llm-v1",
        name="My LLM Model",
        model_type="llm",
        version="1.0.0",
        environment="prod",
        thresholds=Thresholds(
            latency=2000.0,  # 2 seconds
            error_rate=0.01,  # 1%
            gpu_memory=0.85   # 85%
        )
    )
    await client.register_model(config)

    # Collect inference metrics
    await client.collect_inference_metric(
        model_id="my-llm-v1",
        model_type="llm",
        latency=1500.0,
        throughput=10.5,
        error_rate=0.005,
        tags={"version": "1.0.0", "endpoint": "/api/chat"}
    )

    # Get summary statistics
    stats = await client.get_summary_stats("my-llm-v1", since_hours=24)
    print(f"Average latency: {stats['average_latency']:.1f}ms")

asyncio.run(main())
```

### Using Decorators

```python
from monitorx.sdk import MonitorXClient, MonitorXContext, monitor_inference

# Set up client context
client = MonitorXClient("http://localhost:8000")

@monitor_inference(
    model_id="my-cv-model",
    model_type="cv",
    tags={"version": "2.1.0"}
)
async def process_image(image_path: str) -> dict:
    # Your ML inference code here
    # Latency and errors are automatically tracked
    result = await your_model.predict(image_path)
    return result

# Use within context
async def main():
    async with client:
        with MonitorXContext(client):
            result = await process_image("/path/to/image.jpg")
```

### Direct API Usage

```python
import httpx

# Register model
async with httpx.AsyncClient() as client:
    model_config = {
        "id": "fraud-detector-v3",
        "name": "Fraud Detection Model",
        "model_type": "tabular",
        "version": "3.0.0",
        "environment": "prod",
        "thresholds": {
            "latency": 500.0,
            "error_rate": 0.02,
            "cpu_usage": 0.8
        }
    }

    response = await client.post(
        "http://localhost:8000/api/v1/models",
        json=model_config
    )
    print(response.json())

    # Send metrics
    metric = {
        "model_id": "fraud-detector-v3",
        "model_type": "tabular",
        "request_id": "req-123456",
        "latency": 245.0,
        "error_rate": 0.01,
        "tags": {"feature_version": "v2"}
    }

    response = await client.post(
        "http://localhost:8000/api/v1/metrics/inference",
        json=metric
    )
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `INFLUXDB_URL` | InfluxDB server URL | `http://localhost:8086` |
| `INFLUXDB_TOKEN` | InfluxDB access token | Required |
| `INFLUXDB_ORG` | InfluxDB organization | `monitorx` |
| `INFLUXDB_BUCKET` | InfluxDB bucket name | `metrics` |
| `API_HOST` | API server host | `0.0.0.0` |
| `API_PORT` | API server port | `8000` |
| `DASHBOARD_PORT` | Streamlit dashboard port | `8501` |
| `LOG_LEVEL` | Logging level | `INFO` |

**Security note:** demo docker-compose defaults are for local testing only. Set strong values for `INFLUXDB_PASSWORD` and `INFLUXDB_TOKEN` before any real deployment.

### Alert Configuration

```python
from monitorx.services import AlertingService, EmailChannel, SlackChannel

# Set up alerting
alerting = AlertingService()

# Email alerts
email_channel = EmailChannel(
    name="email-alerts",
    smtp_server="smtp.gmail.com",
    smtp_port=587,
    username="your-email@gmail.com",
    password="your-app-password",
    from_email="alerts@yourcompany.com",
    to_emails=["team@yourcompany.com"]
)
alerting.add_channel(email_channel)

# Slack alerts
slack_channel = SlackChannel(
    name="slack-alerts",
    webhook_url="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK",
    channel="#ml-alerts"
)
alerting.add_channel(slack_channel)

# Register with metrics collector
metrics_collector.add_alert_callback(alerting.send_alert)
```

## ğŸ“ˆ Metrics Reference

### Inference Metrics
- **latency**: Request processing time (milliseconds)
- **throughput**: Requests per second
- **error_rate**: Fraction of failed requests (0.0-1.0)
- **resource_usage**: GPU/CPU/memory utilization (0.0-1.0)

### Drift Metrics
- **drift_type**: Type of drift ("data" or "concept")
- **severity**: Drift severity ("low", "medium", "high", "critical")
- **confidence**: Detection confidence (0.0-1.0)

### Alert Types
- **latency**: High response time alerts
- **error_rate**: Error rate threshold breaches
- **drift**: Model drift detection alerts
- **resource_usage**: Resource utilization alerts

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ML Models      â”‚    â”‚    MonitorX      â”‚    â”‚   InfluxDB      â”‚
â”‚                  â”‚â”€â”€â”€â–¶â”‚   FastAPI API    â”‚â”€â”€â”€â–¶â”‚  Time-Series    â”‚
â”‚ â€¢ LLM            â”‚    â”‚                  â”‚    â”‚   Database      â”‚
â”‚ â€¢ Computer Visionâ”‚    â”‚ â€¢ Metrics        â”‚    â”‚                 â”‚
â”‚ â€¢ Tabular        â”‚    â”‚ â€¢ Alerts         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”€â”˜    â”‚ â€¢ Models         â”‚           â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                              â”‚                        â”‚
                              â–¼                        â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Streamlit      â”‚    â”‚   Alerting      â”‚
                    â”‚   Dashboard      â”‚    â”‚   Service       â”‚
                    â”‚                  â”‚    â”‚                 â”‚
                    â”‚ â€¢ Real-time UI   â”‚    â”‚ â€¢ Email         â”‚
                    â”‚ â€¢ Charts         â”‚    â”‚ â€¢ Slack         â”‚
                    â”‚ â€¢ Alerts         â”‚    â”‚ â€¢ Webhooks      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Documentation

- **[API Documentation](docs/API.md)** - Complete REST API reference
- **[SDK Advanced Features](docs/SDK_ADVANCED.md)** - Batch collection, retry, circuit breaker, buffering
- **[Alerting Guide](docs/ALERTING.md)** - Setting up email, Slack, and webhook alerts
- **[Security Guide](docs/SECURITY.md)** - Authentication, rate limiting, production security
- **[Deployment Guide](docs/DEPLOYMENT.md)** - Production deployment and scaling
- **[Architecture Overview](docs/ARCHITECTURE.md)** - System design and components
- **[Testing Guide](TESTING.md)** - Running and writing tests

## ğŸ§ª Testing

MonitorX includes comprehensive test coverage (119 tests):

```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_api.py -v

# Run with coverage
pytest tests/ --cov=monitorx --cov-report=html
```

Test categories:
- **Unit Tests**: Core types, metrics collector, SDK client
- **API Tests**: All REST endpoints with mocked storage
- **Integration Tests**: Alerting service with channel mocking

### âœ… Verify MonitorX is Working As Intended (WAI)

Run the quick verification script to prove all components are working:

```bash
# Quick verification (5 seconds, 23 checks)
./verify_quick.sh
```

**Expected Output**:
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          âœ… MonitorX is Working As Intended (WAI)         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Tests Passed: 23/23
Tests Failed: 0/23
```

For comprehensive verification steps, see:
- **[VERIFICATION_GUIDE.md](VERIFICATION_GUIDE.md)** - Detailed verification steps (5-30 min)
- **[PROOF_OF_WAI.md](PROOF_OF_WAI.md)** - Complete evidence and test results

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Setup

```bash
# Install development dependencies
pip install -e ".[dev]"

# Run tests
pytest tests/ -v

# Format code
black src/ tests/
isort src/ tests/

# Type check
mypy src/
```

## ğŸ“œ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

```
Copyright 2025 MonitorX Team

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```

## ğŸ†˜ Support

- **Documentation**: Visit our [docs](docs/) for detailed guides
- **Issues**: Report bugs or request features on [GitHub Issues](https://github.com/your-org/monitorx/issues)
- **Discussions**: Join the community on [GitHub Discussions](https://github.com/your-org/monitorx/discussions)

---

**MonitorX v0.1.0** - Built with â¤ï¸ for the ML community
